{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1/100 epochs: 100%|██████████| 59/59 [00:19<00:00,  3.09it/s, train_advacc=0.291, train_advloss=1.98, val_advacc=0.451, val_advloss=1.54]\n",
      "2/100 epochs: 100%|██████████| 59/59 [00:19<00:00,  3.10it/s, train_advacc=0.521, train_advloss=1.38, val_advacc=0.562, val_advloss=1.17]\n",
      "3/100 epochs: 100%|██████████| 59/59 [00:18<00:00,  3.12it/s, train_advacc=0.604, train_advloss=1.13, val_advacc=0.627, val_advloss=0.98] \n",
      "4/100 epochs: 100%|██████████| 59/59 [00:18<00:00,  3.15it/s, train_advacc=0.661, train_advloss=0.983, val_advacc=0.67, val_advloss=0.843] \n",
      "5/100 epochs: 100%|██████████| 59/59 [00:18<00:00,  3.11it/s, train_advacc=0.701, train_advloss=0.873, val_advacc=0.709, val_advloss=0.764]\n",
      "6/100 epochs: 100%|██████████| 59/59 [00:18<00:00,  3.14it/s, train_advacc=0.732, train_advloss=0.79, val_advacc=0.762, val_advloss=0.668]\n",
      "7/100 epochs: 100%|██████████| 59/59 [00:18<00:00,  3.14it/s, train_advacc=0.76, train_advloss=0.714, val_advacc=0.787, val_advloss=0.604]\n",
      "8/100 epochs: 100%|██████████| 59/59 [00:18<00:00,  3.15it/s, train_advacc=0.782, train_advloss=0.652, val_advacc=0.801, val_advloss=0.554]\n",
      "9/100 epochs: 100%|██████████| 59/59 [00:18<00:00,  3.15it/s, train_advacc=0.799, train_advloss=0.608, val_advacc=0.826, val_advloss=0.501]\n",
      "10/100 epochs: 100%|██████████| 59/59 [00:18<00:00,  3.15it/s, train_advacc=0.815, train_advloss=0.563, val_advacc=0.828, val_advloss=0.456]\n",
      "11/100 epochs: 100%|██████████| 59/59 [00:19<00:00,  3.10it/s, train_advacc=0.828, train_advloss=0.521, val_advacc=0.85, val_advloss=0.417] \n",
      "12/100 epochs: 100%|██████████| 59/59 [00:18<00:00,  3.15it/s, train_advacc=0.84, train_advloss=0.49, val_advacc=0.865, val_advloss=0.386]\n",
      "13/100 epochs: 100%|██████████| 59/59 [00:18<00:00,  3.16it/s, train_advacc=0.85, train_advloss=0.461, val_advacc=0.869, val_advloss=0.361]\n",
      "14/100 epochs: 100%|██████████| 59/59 [00:18<00:00,  3.14it/s, train_advacc=0.86, train_advloss=0.433, val_advacc=0.875, val_advloss=0.34] \n",
      "15/100 epochs: 100%|██████████| 59/59 [00:18<00:00,  3.14it/s, train_advacc=0.868, train_advloss=0.41, val_advacc=0.893, val_advloss=0.321]\n",
      "16/100 epochs: 100%|██████████| 59/59 [00:18<00:00,  3.15it/s, train_advacc=0.875, train_advloss=0.392, val_advacc=0.891, val_advloss=0.3]  \n",
      "17/100 epochs: 100%|██████████| 59/59 [00:18<00:00,  3.15it/s, train_advacc=0.882, train_advloss=0.372, val_advacc=0.902, val_advloss=0.285]\n",
      "18/100 epochs: 100%|██████████| 59/59 [00:18<00:00,  3.15it/s, train_advacc=0.885, train_advloss=0.359, val_advacc=0.9, val_advloss=0.272]  \n",
      "19/100 epochs: 100%|██████████| 59/59 [00:18<00:00,  3.15it/s, train_advacc=0.889, train_advloss=0.343, val_advacc=0.908, val_advloss=0.268]\n",
      "20/100 epochs: 100%|██████████| 59/59 [00:18<00:00,  3.15it/s, train_advacc=0.896, train_advloss=0.329, val_advacc=0.91, val_advloss=0.257] \n",
      "21/100 epochs: 100%|██████████| 59/59 [00:18<00:00,  3.15it/s, train_advacc=0.898, train_advloss=0.321, val_advacc=0.912, val_advloss=0.245]\n",
      "22/100 epochs: 100%|██████████| 59/59 [00:18<00:00,  3.14it/s, train_advacc=0.902, train_advloss=0.313, val_advacc=0.92, val_advloss=0.23]  \n",
      "23/100 epochs: 100%|██████████| 59/59 [00:18<00:00,  3.15it/s, train_advacc=0.904, train_advloss=0.305, val_advacc=0.924, val_advloss=0.233]\n",
      "24/100 epochs: 100%|██████████| 59/59 [00:18<00:00,  3.15it/s, train_advacc=0.905, train_advloss=0.296, val_advacc=0.928, val_advloss=0.225]\n",
      "25/100 epochs: 100%|██████████| 59/59 [00:18<00:00,  3.15it/s, train_advacc=0.908, train_advloss=0.289, val_advacc=0.93, val_advloss=0.215] \n",
      "26/100 epochs: 100%|██████████| 59/59 [00:18<00:00,  3.16it/s, train_advacc=0.909, train_advloss=0.282, val_advacc=0.928, val_advloss=0.211]\n",
      "27/100 epochs: 100%|██████████| 59/59 [00:18<00:00,  3.14it/s, train_advacc=0.912, train_advloss=0.276, val_advacc=0.932, val_advloss=0.203]\n",
      "28/100 epochs: 100%|██████████| 59/59 [00:18<00:00,  3.15it/s, train_advacc=0.914, train_advloss=0.27, val_advacc=0.932, val_advloss=0.202]\n",
      "29/100 epochs: 100%|██████████| 59/59 [00:18<00:00,  3.16it/s, train_advacc=0.916, train_advloss=0.264, val_advacc=0.928, val_advloss=0.207]\n",
      "30/100 epochs: 100%|██████████| 59/59 [00:18<00:00,  3.15it/s, train_advacc=0.918, train_advloss=0.261, val_advacc=0.928, val_advloss=0.198]\n",
      "31/100 epochs: 100%|██████████| 59/59 [00:18<00:00,  3.15it/s, train_advacc=0.919, train_advloss=0.254, val_advacc=0.934, val_advloss=0.195]\n",
      "32/100 epochs: 100%|██████████| 59/59 [00:18<00:00,  3.15it/s, train_advacc=0.921, train_advloss=0.249, val_advacc=0.941, val_advloss=0.181] \n",
      "33/100 epochs: 100%|██████████| 59/59 [00:18<00:00,  3.15it/s, train_advacc=0.921, train_advloss=0.248, val_advacc=0.938, val_advloss=0.186] \n",
      "34/100 epochs: 100%|██████████| 59/59 [00:18<00:00,  3.14it/s, train_advacc=0.923, train_advloss=0.241, val_advacc=0.941, val_advloss=0.181]\n",
      "35/100 epochs: 100%|██████████| 59/59 [00:18<00:00,  3.15it/s, train_advacc=0.925, train_advloss=0.237, val_advacc=0.945, val_advloss=0.174] \n",
      "36/100 epochs: 100%|██████████| 59/59 [00:18<00:00,  3.16it/s, train_advacc=0.925, train_advloss=0.235, val_advacc=0.945, val_advloss=0.18] \n",
      "37/100 epochs: 100%|██████████| 59/59 [00:18<00:00,  3.14it/s, train_advacc=0.926, train_advloss=0.232, val_advacc=0.943, val_advloss=0.174] \n",
      "38/100 epochs: 100%|██████████| 59/59 [00:19<00:00,  3.02it/s, train_advacc=0.927, train_advloss=0.227, val_advacc=0.943, val_advloss=0.161] \n",
      "39/100 epochs: 100%|██████████| 59/59 [00:19<00:00,  2.99it/s, train_advacc=0.929, train_advloss=0.224, val_advacc=0.939, val_advloss=0.173] \n",
      "40/100 epochs: 100%|██████████| 59/59 [00:19<00:00,  2.99it/s, train_advacc=0.93, train_advloss=0.221, val_advacc=0.947, val_advloss=0.167] \n",
      "41/100 epochs: 100%|██████████| 59/59 [00:19<00:00,  2.99it/s, train_advacc=0.931, train_advloss=0.219, val_advacc=0.945, val_advloss=0.163]\n",
      "42/100 epochs: 100%|██████████| 59/59 [00:19<00:00,  2.99it/s, train_advacc=0.93, train_advloss=0.22, val_advacc=0.951, val_advloss=0.166]\n",
      "43/100 epochs: 100%|██████████| 59/59 [00:18<00:00,  3.15it/s, train_advacc=0.932, train_advloss=0.214, val_advacc=0.949, val_advloss=0.166] \n",
      "44/100 epochs: 100%|██████████| 59/59 [00:18<00:00,  3.14it/s, train_advacc=0.934, train_advloss=0.208, val_advacc=0.949, val_advloss=0.161] \n",
      "45/100 epochs: 100%|██████████| 59/59 [00:18<00:00,  3.16it/s, train_advacc=0.934, train_advloss=0.21, val_advacc=0.949, val_advloss=0.159] \n",
      "46/100 epochs: 100%|██████████| 59/59 [00:18<00:00,  3.15it/s, train_advacc=0.934, train_advloss=0.211, val_advacc=0.949, val_advloss=0.155] \n",
      "47/100 epochs: 100%|██████████| 59/59 [00:18<00:00,  3.14it/s, train_advacc=0.935, train_advloss=0.203, val_advacc=0.951, val_advloss=0.153] \n",
      "48/100 epochs: 100%|██████████| 59/59 [00:18<00:00,  3.15it/s, train_advacc=0.934, train_advloss=0.206, val_advacc=0.951, val_advloss=0.161] \n",
      "49/100 epochs: 100%|██████████| 59/59 [00:18<00:00,  3.15it/s, train_advacc=0.937, train_advloss=0.2, val_advacc=0.951, val_advloss=0.149] \n",
      "50/100 epochs: 100%|██████████| 59/59 [00:18<00:00,  3.15it/s, train_advacc=0.936, train_advloss=0.201, val_advacc=0.953, val_advloss=0.159] \n",
      "51/100 epochs: 100%|██████████| 59/59 [00:18<00:00,  3.13it/s, train_advacc=0.937, train_advloss=0.197, val_advacc=0.953, val_advloss=0.148] \n",
      "52/100 epochs: 100%|██████████| 59/59 [00:18<00:00,  3.15it/s, train_advacc=0.937, train_advloss=0.199, val_advacc=0.951, val_advloss=0.148] \n",
      "53/100 epochs: 100%|██████████| 59/59 [00:18<00:00,  3.15it/s, train_advacc=0.936, train_advloss=0.2, val_advacc=0.951, val_advloss=0.155] \n",
      "54/100 epochs: 100%|██████████| 59/59 [00:19<00:00,  2.99it/s, train_advacc=0.938, train_advloss=0.193, val_advacc=0.955, val_advloss=0.153] \n",
      "55/100 epochs: 100%|██████████| 59/59 [00:19<00:00,  3.09it/s, train_advacc=0.938, train_advloss=0.193, val_advacc=0.949, val_advloss=0.147] \n",
      "56/100 epochs: 100%|██████████| 59/59 [00:18<00:00,  3.14it/s, train_advacc=0.939, train_advloss=0.192, val_advacc=0.955, val_advloss=0.151] \n",
      "57/100 epochs: 100%|██████████| 59/59 [00:18<00:00,  3.15it/s, train_advacc=0.94, train_advloss=0.19, val_advacc=0.949, val_advloss=0.15]  \n",
      "58/100 epochs: 100%|██████████| 59/59 [00:18<00:00,  3.14it/s, train_advacc=0.939, train_advloss=0.19, val_advacc=0.955, val_advloss=0.156] \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "59/100 epochs: 100%|██████████| 59/59 [00:18<00:00,  3.15it/s, train_advacc=0.939, train_advloss=0.189, val_advacc=0.951, val_advloss=0.149] \n",
      "60/100 epochs: 100%|██████████| 59/59 [00:18<00:00,  3.15it/s, train_advacc=0.94, train_advloss=0.188, val_advacc=0.949, val_advloss=0.146] \n",
      "61/100 epochs: 100%|██████████| 59/59 [00:18<00:00,  3.15it/s, train_advacc=0.94, train_advloss=0.188, val_advacc=0.947, val_advloss=0.152] \n",
      "62/100 epochs: 100%|██████████| 59/59 [00:18<00:00,  3.16it/s, train_advacc=0.941, train_advloss=0.187, val_advacc=0.947, val_advloss=0.144] \n",
      "63/100 epochs: 100%|██████████| 59/59 [00:18<00:00,  3.15it/s, train_advacc=0.94, train_advloss=0.186, val_advacc=0.949, val_advloss=0.156] \n",
      "64/100 epochs: 100%|██████████| 59/59 [00:18<00:00,  3.15it/s, train_advacc=0.942, train_advloss=0.185, val_advacc=0.947, val_advloss=0.15]  \n",
      "65/100 epochs: 100%|██████████| 59/59 [00:18<00:00,  3.15it/s, train_advacc=0.94, train_advloss=0.184, val_advacc=0.949, val_advloss=0.157] \n",
      "66/100 epochs: 100%|██████████| 59/59 [00:18<00:00,  3.15it/s, train_advacc=0.941, train_advloss=0.187, val_advacc=0.949, val_advloss=0.152] \n",
      "67/100 epochs: 100%|██████████| 59/59 [00:18<00:00,  3.15it/s, train_advacc=0.942, train_advloss=0.183, val_advacc=0.947, val_advloss=0.148] \n",
      "68/100 epochs: 100%|██████████| 59/59 [00:18<00:00,  3.15it/s, train_advacc=0.943, train_advloss=0.181, val_advacc=0.951, val_advloss=0.151] \n",
      "69/100 epochs: 100%|██████████| 59/59 [00:18<00:00,  3.16it/s, train_advacc=0.943, train_advloss=0.181, val_advacc=0.949, val_advloss=0.139] \n",
      "70/100 epochs: 100%|██████████| 59/59 [00:18<00:00,  3.15it/s, train_advacc=0.943, train_advloss=0.18, val_advacc=0.945, val_advloss=0.145] \n",
      "71/100 epochs: 100%|██████████| 59/59 [00:18<00:00,  3.14it/s, train_advacc=0.943, train_advloss=0.179, val_advacc=0.949, val_advloss=0.146] \n",
      "72/100 epochs: 100%|██████████| 59/59 [00:18<00:00,  3.15it/s, train_advacc=0.943, train_advloss=0.18, val_advacc=0.947, val_advloss=0.156] \n",
      "73/100 epochs: 100%|██████████| 59/59 [00:18<00:00,  3.15it/s, train_advacc=0.944, train_advloss=0.176, val_advacc=0.949, val_advloss=0.143] \n",
      "74/100 epochs: 100%|██████████| 59/59 [00:18<00:00,  3.15it/s, train_advacc=0.942, train_advloss=0.178, val_advacc=0.945, val_advloss=0.146]\n",
      "75/100 epochs: 100%|██████████| 59/59 [00:18<00:00,  3.14it/s, train_advacc=0.944, train_advloss=0.176, val_advacc=0.955, val_advloss=0.142] \n",
      "76/100 epochs: 100%|██████████| 59/59 [00:18<00:00,  3.15it/s, train_advacc=0.943, train_advloss=0.178, val_advacc=0.947, val_advloss=0.144] \n",
      "77/100 epochs: 100%|██████████| 59/59 [00:18<00:00,  3.15it/s, train_advacc=0.944, train_advloss=0.174, val_advacc=0.951, val_advloss=0.149] \n",
      "78/100 epochs: 100%|██████████| 59/59 [00:18<00:00,  3.15it/s, train_advacc=0.945, train_advloss=0.171, val_advacc=0.951, val_advloss=0.141] \n",
      "79/100 epochs: 100%|██████████| 59/59 [00:18<00:00,  3.15it/s, train_advacc=0.943, train_advloss=0.176, val_advacc=0.947, val_advloss=0.141] \n",
      "80/100 epochs: 100%|██████████| 59/59 [00:18<00:00,  3.15it/s, train_advacc=0.943, train_advloss=0.175, val_advacc=0.953, val_advloss=0.145] \n",
      "81/100 epochs: 100%|██████████| 59/59 [00:18<00:00,  3.16it/s, train_advacc=0.945, train_advloss=0.172, val_advacc=0.951, val_advloss=0.142] \n",
      "82/100 epochs: 100%|██████████| 59/59 [00:18<00:00,  3.14it/s, train_advacc=0.945, train_advloss=0.173, val_advacc=0.951, val_advloss=0.142] \n",
      "83/100 epochs: 100%|██████████| 59/59 [00:18<00:00,  3.16it/s, train_advacc=0.944, train_advloss=0.174, val_advacc=0.953, val_advloss=0.147] \n",
      "84/100 epochs: 100%|██████████| 59/59 [00:18<00:00,  3.15it/s, train_advacc=0.945, train_advloss=0.17, val_advacc=0.953, val_advloss=0.146] \n",
      "85/100 epochs: 100%|██████████| 59/59 [00:18<00:00,  3.15it/s, train_advacc=0.944, train_advloss=0.172, val_advacc=0.947, val_advloss=0.149] \n",
      "86/100 epochs: 100%|██████████| 59/59 [00:18<00:00,  3.15it/s, train_advacc=0.946, train_advloss=0.172, val_advacc=0.951, val_advloss=0.145] \n",
      "87/100 epochs: 100%|██████████| 59/59 [00:18<00:00,  3.15it/s, train_advacc=0.945, train_advloss=0.173, val_advacc=0.949, val_advloss=0.152] \n",
      "88/100 epochs: 100%|██████████| 59/59 [00:18<00:00,  3.16it/s, train_advacc=0.945, train_advloss=0.171, val_advacc=0.949, val_advloss=0.147] \n",
      "89/100 epochs: 100%|██████████| 59/59 [00:18<00:00,  3.14it/s, train_advacc=0.945, train_advloss=0.17, val_advacc=0.955, val_advloss=0.14]  \n",
      "90/100 epochs: 100%|██████████| 59/59 [00:18<00:00,  3.14it/s, train_advacc=0.947, train_advloss=0.165, val_advacc=0.959, val_advloss=0.136] \n",
      "91/100 epochs: 100%|██████████| 59/59 [00:18<00:00,  3.16it/s, train_advacc=0.947, train_advloss=0.165, val_advacc=0.947, val_advloss=0.148] \n",
      "92/100 epochs: 100%|██████████| 59/59 [00:18<00:00,  3.15it/s, train_advacc=0.945, train_advloss=0.168, val_advacc=0.955, val_advloss=0.135] \n",
      "93/100 epochs: 100%|██████████| 59/59 [00:18<00:00,  3.14it/s, train_advacc=0.947, train_advloss=0.164, val_advacc=0.951, val_advloss=0.143] \n",
      "94/100 epochs: 100%|██████████| 59/59 [00:18<00:00,  3.16it/s, train_advacc=0.947, train_advloss=0.165, val_advacc=0.947, val_advloss=0.142] \n",
      "95/100 epochs: 100%|██████████| 59/59 [00:18<00:00,  3.15it/s, train_advacc=0.947, train_advloss=0.164, val_advacc=0.955, val_advloss=0.147] \n",
      "96/100 epochs: 100%|██████████| 59/59 [00:18<00:00,  3.15it/s, train_advacc=0.947, train_advloss=0.166, val_advacc=0.951, val_advloss=0.142] \n",
      "97/100 epochs: 100%|██████████| 59/59 [00:18<00:00,  3.15it/s, train_advacc=0.946, train_advloss=0.166, val_advacc=0.953, val_advloss=0.149] \n",
      "98/100 epochs: 100%|██████████| 59/59 [00:18<00:00,  3.15it/s, train_advacc=0.948, train_advloss=0.163, val_advacc=0.951, val_advloss=0.151] \n",
      "99/100 epochs: 100%|██████████| 59/59 [00:18<00:00,  3.15it/s, train_advacc=0.948, train_advloss=0.162, val_advacc=0.953, val_advloss=0.141] \n",
      "100/100 epochs: 100%|██████████| 59/59 [00:19<00:00,  3.09it/s, train_advacc=0.947, train_advloss=0.164, val_advacc=0.953, val_advloss=0.15]  \n"
     ]
    }
   ],
   "source": [
    "from models.cnn import CNN\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.optim import Adam, lr_scheduler\n",
    "from torchvision import datasets,transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "from pgd import PGD\n",
    "\n",
    "device = torch.device(\"cuda\")\n",
    "root = \"./datasets\"\n",
    "download = os.path.exists(\"./datasets/MNIST\")\n",
    "\n",
    "model = CNN()\n",
    "model.to(device)\n",
    "\n",
    "trainset = datasets.MNIST(root=\"./datasets\", download=download, train=True, transform=transforms.ToTensor())\n",
    "testset = datasets.MNIST(root=\"./datasets\", download=download, train=False, transform=transforms.ToTensor())\n",
    "trainloader = DataLoader(trainset, shuffle=True, batch_size=1024)\n",
    "testloader = DataLoader(testset, shuffle=False, batch_size=128)\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = Adam(model.parameters(),lr=1e-3)\n",
    "\n",
    "pgd = PGD(eps=60/255, step_size=20/255, max_iter=10, random_init=True, batch_size=128)\n",
    "\n",
    "epochs = 100\n",
    "best_val_acc = 0\n",
    "for e in range(epochs):\n",
    "    with tqdm(trainloader,desc=f\"{e+1}/{epochs} epochs\") as t:\n",
    "        running_correct = 0\n",
    "        running_loss = 0\n",
    "        running_total = 0\n",
    "        model.train()\n",
    "        for i, (x,y) in enumerate(t):\n",
    "            x_adv = pgd.generate(model,x,y,device=device)\n",
    "            model.train()\n",
    "            out = model(x_adv.to(device))\n",
    "            loss = loss_fn(out,y.to(device))\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_correct += (out.max(dim=1)[1]==y.to(device)).sum().item()\n",
    "            running_loss += loss.item()*x.size(0)\n",
    "            running_total += x.size(0)\n",
    "            if i < len(trainloader)-1:\n",
    "                t.set_postfix({\n",
    "                    \"train_advacc\": running_correct/running_total,\n",
    "                    \"train_advloss\": running_loss/running_total\n",
    "                })\n",
    "            else:\n",
    "                model.eval()\n",
    "                val_correct = 0\n",
    "                val_loss = 0\n",
    "                val_total = 0\n",
    "                for _, (x,y) in zip(range(4),testloader):\n",
    "                    x_adv = pgd.generate(model,x,y,device=device)\n",
    "                    with torch.no_grad():\n",
    "                        out = model(x_adv.to(device))\n",
    "                        loss = loss_fn(out,y.to(device))\n",
    "                    val_correct += (out.max(dim=1)[1]==y.to(device)).sum().item()\n",
    "                    val_loss += loss.item()*x.size(0)\n",
    "                    val_total += x.size(0)\n",
    "                    t.set_postfix({\n",
    "                        \"train_advacc\": running_correct/running_total,\n",
    "                        \"train_advloss\": running_loss/running_total,\n",
    "                        \"val_advacc\": val_correct/val_total,\n",
    "                        \"val_advloss\": val_loss/val_total\n",
    "                    })\n",
    "                if val_correct/val_total >= best_val_acc:\n",
    "                    best_val_acc = val_correct/val_total\n",
    "                    torch.save(model.state_dict(), \"./model_weights/mnist_cnn_adv.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
