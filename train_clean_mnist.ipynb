{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1/100 epochs: 100%|██████████| 59/59 [00:04<00:00, 12.58it/s, train_acc=0.793, train_loss=0.658, val_acc=0.951, val_loss=0.154] \n",
      "2/100 epochs: 100%|██████████| 59/59 [00:04<00:00, 12.38it/s, train_acc=0.938, train_loss=0.21, val_acc=0.975, val_loss=0.0944]\n",
      "3/100 epochs: 100%|██████████| 59/59 [00:04<00:00, 12.29it/s, train_acc=0.957, train_loss=0.147, val_acc=0.979, val_loss=0.0642]\n",
      "4/100 epochs: 100%|██████████| 59/59 [00:04<00:00, 12.39it/s, train_acc=0.966, train_loss=0.116, val_acc=0.982, val_loss=0.0554]\n",
      "5/100 epochs: 100%|██████████| 59/59 [00:04<00:00, 12.30it/s, train_acc=0.97, train_loss=0.103, val_acc=0.98, val_loss=0.0494] \n",
      "6/100 epochs: 100%|██████████| 59/59 [00:04<00:00, 12.69it/s, train_acc=0.974, train_loss=0.0875, val_acc=0.986, val_loss=0.0395]\n",
      "7/100 epochs: 100%|██████████| 59/59 [00:04<00:00, 12.53it/s, train_acc=0.976, train_loss=0.0793, val_acc=0.988, val_loss=0.0366]\n",
      "8/100 epochs: 100%|██████████| 59/59 [00:04<00:00, 12.50it/s, train_acc=0.978, train_loss=0.0716, val_acc=0.988, val_loss=0.0335]\n",
      "9/100 epochs: 100%|██████████| 59/59 [00:04<00:00, 12.65it/s, train_acc=0.98, train_loss=0.0663, val_acc=0.988, val_loss=0.0312] \n",
      "10/100 epochs: 100%|██████████| 59/59 [00:04<00:00, 12.47it/s, train_acc=0.981, train_loss=0.0641, val_acc=0.992, val_loss=0.0244]\n",
      "11/100 epochs: 100%|██████████| 59/59 [00:04<00:00, 12.68it/s, train_acc=0.982, train_loss=0.0583, val_acc=0.994, val_loss=0.0256]\n",
      "12/100 epochs: 100%|██████████| 59/59 [00:04<00:00, 12.63it/s, train_acc=0.983, train_loss=0.0546, val_acc=0.988, val_loss=0.0276]\n",
      "13/100 epochs: 100%|██████████| 59/59 [00:04<00:00, 12.70it/s, train_acc=0.983, train_loss=0.0533, val_acc=0.99, val_loss=0.0211] \n",
      "14/100 epochs: 100%|██████████| 59/59 [00:04<00:00, 12.36it/s, train_acc=0.985, train_loss=0.0469, val_acc=0.992, val_loss=0.018] \n",
      "15/100 epochs: 100%|██████████| 59/59 [00:04<00:00, 11.81it/s, train_acc=0.985, train_loss=0.0476, val_acc=0.99, val_loss=0.0206] \n",
      "16/100 epochs: 100%|██████████| 59/59 [00:05<00:00, 10.34it/s, train_acc=0.986, train_loss=0.0438, val_acc=0.988, val_loss=0.0221] \n",
      "17/100 epochs: 100%|██████████| 59/59 [00:04<00:00, 12.09it/s, train_acc=0.987, train_loss=0.044, val_acc=0.994, val_loss=0.0161] \n",
      "18/100 epochs: 100%|██████████| 59/59 [00:05<00:00, 11.01it/s, train_acc=0.987, train_loss=0.0416, val_acc=0.996, val_loss=0.0199]\n",
      "19/100 epochs: 100%|██████████| 59/59 [00:04<00:00, 12.50it/s, train_acc=0.988, train_loss=0.0393, val_acc=0.99, val_loss=0.0209] \n",
      "20/100 epochs: 100%|██████████| 59/59 [00:05<00:00, 11.71it/s, train_acc=0.988, train_loss=0.0391, val_acc=0.994, val_loss=0.0162] \n",
      "21/100 epochs: 100%|██████████| 59/59 [00:04<00:00, 12.47it/s, train_acc=0.989, train_loss=0.0371, val_acc=0.99, val_loss=0.0176]  \n",
      "22/100 epochs: 100%|██████████| 59/59 [00:04<00:00, 12.62it/s, train_acc=0.988, train_loss=0.0364, val_acc=0.992, val_loss=0.024] \n",
      "23/100 epochs: 100%|██████████| 59/59 [00:05<00:00, 10.41it/s, train_acc=0.989, train_loss=0.0347, val_acc=0.992, val_loss=0.0158] \n",
      "24/100 epochs: 100%|██████████| 59/59 [00:05<00:00, 10.51it/s, train_acc=0.989, train_loss=0.0354, val_acc=0.994, val_loss=0.0135]\n",
      "25/100 epochs: 100%|██████████| 59/59 [00:04<00:00, 12.55it/s, train_acc=0.99, train_loss=0.0322, val_acc=0.992, val_loss=0.0176] \n",
      "26/100 epochs: 100%|██████████| 59/59 [00:04<00:00, 12.51it/s, train_acc=0.99, train_loss=0.0315, val_acc=0.988, val_loss=0.0214] \n",
      "27/100 epochs: 100%|██████████| 59/59 [00:05<00:00, 10.94it/s, train_acc=0.99, train_loss=0.0321, val_acc=0.994, val_loss=0.0149]\n",
      "28/100 epochs: 100%|██████████| 59/59 [00:05<00:00, 10.75it/s, train_acc=0.991, train_loss=0.029, val_acc=0.992, val_loss=0.0143] \n",
      "29/100 epochs: 100%|██████████| 59/59 [00:04<00:00, 12.64it/s, train_acc=0.991, train_loss=0.0298, val_acc=0.994, val_loss=0.0163]\n",
      "30/100 epochs: 100%|██████████| 59/59 [00:04<00:00, 12.56it/s, train_acc=0.99, train_loss=0.0294, val_acc=0.994, val_loss=0.0178]\n",
      "31/100 epochs: 100%|██████████| 59/59 [00:04<00:00, 12.44it/s, train_acc=0.991, train_loss=0.028, val_acc=0.996, val_loss=0.0121] \n",
      "32/100 epochs: 100%|██████████| 59/59 [00:04<00:00, 12.56it/s, train_acc=0.991, train_loss=0.0281, val_acc=0.994, val_loss=0.0142]\n",
      "33/100 epochs: 100%|██████████| 59/59 [00:04<00:00, 12.63it/s, train_acc=0.992, train_loss=0.0262, val_acc=0.996, val_loss=0.0135] \n",
      "34/100 epochs: 100%|██████████| 59/59 [00:04<00:00, 12.65it/s, train_acc=0.992, train_loss=0.0266, val_acc=0.992, val_loss=0.0233] \n",
      "35/100 epochs: 100%|██████████| 59/59 [00:04<00:00, 12.70it/s, train_acc=0.992, train_loss=0.0254, val_acc=0.996, val_loss=0.0221]\n",
      "36/100 epochs: 100%|██████████| 59/59 [00:04<00:00, 12.52it/s, train_acc=0.991, train_loss=0.0265, val_acc=0.992, val_loss=0.0189]\n",
      "37/100 epochs: 100%|██████████| 59/59 [00:04<00:00, 12.57it/s, train_acc=0.992, train_loss=0.0237, val_acc=0.99, val_loss=0.0242] \n",
      "38/100 epochs: 100%|██████████| 59/59 [00:04<00:00, 12.55it/s, train_acc=0.992, train_loss=0.0243, val_acc=0.988, val_loss=0.0167]\n",
      "39/100 epochs: 100%|██████████| 59/59 [00:04<00:00, 12.52it/s, train_acc=0.992, train_loss=0.023, val_acc=0.994, val_loss=0.019] \n",
      "40/100 epochs: 100%|██████████| 59/59 [00:04<00:00, 12.22it/s, train_acc=0.992, train_loss=0.0237, val_acc=0.992, val_loss=0.0166]\n",
      "41/100 epochs: 100%|██████████| 59/59 [00:04<00:00, 12.61it/s, train_acc=0.992, train_loss=0.0233, val_acc=0.99, val_loss=0.0172]  \n",
      "42/100 epochs: 100%|██████████| 59/59 [00:04<00:00, 12.16it/s, train_acc=0.992, train_loss=0.0238, val_acc=0.992, val_loss=0.018] \n",
      "43/100 epochs: 100%|██████████| 59/59 [00:04<00:00, 12.15it/s, train_acc=0.992, train_loss=0.0238, val_acc=0.994, val_loss=0.0134] \n",
      "44/100 epochs: 100%|██████████| 59/59 [00:04<00:00, 12.69it/s, train_acc=0.993, train_loss=0.0222, val_acc=0.994, val_loss=0.0103] \n",
      "45/100 epochs: 100%|██████████| 59/59 [00:04<00:00, 12.18it/s, train_acc=0.992, train_loss=0.023, val_acc=0.996, val_loss=0.0119] \n",
      "46/100 epochs: 100%|██████████| 59/59 [00:04<00:00, 12.55it/s, train_acc=0.993, train_loss=0.0219, val_acc=0.996, val_loss=0.00942]\n",
      "47/100 epochs: 100%|██████████| 59/59 [00:04<00:00, 12.72it/s, train_acc=0.993, train_loss=0.0207, val_acc=0.992, val_loss=0.0105] \n",
      "48/100 epochs: 100%|██████████| 59/59 [00:04<00:00, 12.47it/s, train_acc=0.994, train_loss=0.0196, val_acc=0.998, val_loss=0.00671]\n",
      "49/100 epochs: 100%|██████████| 59/59 [00:04<00:00, 12.72it/s, train_acc=0.993, train_loss=0.0207, val_acc=0.994, val_loss=0.00943]\n",
      "50/100 epochs: 100%|██████████| 59/59 [00:04<00:00, 12.69it/s, train_acc=0.994, train_loss=0.0188, val_acc=0.99, val_loss=0.0181]  \n",
      "51/100 epochs: 100%|██████████| 59/59 [00:04<00:00, 12.71it/s, train_acc=0.993, train_loss=0.0201, val_acc=0.996, val_loss=0.0108] \n",
      "52/100 epochs: 100%|██████████| 59/59 [00:04<00:00, 12.77it/s, train_acc=0.994, train_loss=0.0187, val_acc=0.992, val_loss=0.0113] \n",
      "53/100 epochs: 100%|██████████| 59/59 [00:04<00:00, 12.70it/s, train_acc=0.994, train_loss=0.0193, val_acc=0.994, val_loss=0.00778]\n",
      "54/100 epochs: 100%|██████████| 59/59 [00:04<00:00, 12.63it/s, train_acc=0.994, train_loss=0.0195, val_acc=0.996, val_loss=0.0151]\n",
      "55/100 epochs: 100%|██████████| 59/59 [00:04<00:00, 12.57it/s, train_acc=0.994, train_loss=0.0182, val_acc=0.996, val_loss=0.0132] \n",
      "56/100 epochs: 100%|██████████| 59/59 [00:04<00:00, 12.64it/s, train_acc=0.994, train_loss=0.0196, val_acc=0.996, val_loss=0.0131] \n",
      "57/100 epochs: 100%|██████████| 59/59 [00:04<00:00, 12.70it/s, train_acc=0.994, train_loss=0.0185, val_acc=0.994, val_loss=0.0166]\n",
      "58/100 epochs: 100%|██████████| 59/59 [00:04<00:00, 12.69it/s, train_acc=0.994, train_loss=0.0183, val_acc=0.994, val_loss=0.0137] \n",
      "59/100 epochs: 100%|██████████| 59/59 [00:04<00:00, 12.53it/s, train_acc=0.994, train_loss=0.0177, val_acc=0.998, val_loss=0.00447]\n",
      "60/100 epochs: 100%|██████████| 59/59 [00:05<00:00, 10.04it/s, train_acc=0.994, train_loss=0.0191, val_acc=0.998, val_loss=0.0106]\n",
      "61/100 epochs: 100%|██████████| 59/59 [00:04<00:00, 12.52it/s, train_acc=0.994, train_loss=0.0188, val_acc=0.996, val_loss=0.0111] \n",
      "62/100 epochs: 100%|██████████| 59/59 [00:04<00:00, 12.61it/s, train_acc=0.994, train_loss=0.0166, val_acc=0.994, val_loss=0.0187]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "63/100 epochs: 100%|██████████| 59/59 [00:04<00:00, 12.72it/s, train_acc=0.995, train_loss=0.0165, val_acc=0.996, val_loss=0.0125] \n",
      "64/100 epochs: 100%|██████████| 59/59 [00:04<00:00, 12.14it/s, train_acc=0.994, train_loss=0.0166, val_acc=0.996, val_loss=0.0108] \n",
      "65/100 epochs: 100%|██████████| 59/59 [00:04<00:00, 12.17it/s, train_acc=0.994, train_loss=0.0173, val_acc=0.994, val_loss=0.0145] \n",
      "66/100 epochs: 100%|██████████| 59/59 [00:04<00:00, 12.76it/s, train_acc=0.995, train_loss=0.0159, val_acc=0.994, val_loss=0.00969]\n",
      "67/100 epochs: 100%|██████████| 59/59 [00:04<00:00, 12.75it/s, train_acc=0.995, train_loss=0.0176, val_acc=0.994, val_loss=0.0142] \n",
      "68/100 epochs: 100%|██████████| 59/59 [00:04<00:00, 12.67it/s, train_acc=0.994, train_loss=0.0175, val_acc=0.996, val_loss=0.0111] \n",
      "69/100 epochs: 100%|██████████| 59/59 [00:05<00:00, 11.77it/s, train_acc=0.995, train_loss=0.0163, val_acc=0.992, val_loss=0.0126] \n",
      "70/100 epochs: 100%|██████████| 59/59 [00:04<00:00, 12.70it/s, train_acc=0.995, train_loss=0.0175, val_acc=0.994, val_loss=0.0127] \n",
      "71/100 epochs: 100%|██████████| 59/59 [00:04<00:00, 12.77it/s, train_acc=0.995, train_loss=0.0161, val_acc=0.996, val_loss=0.0109] \n",
      "72/100 epochs: 100%|██████████| 59/59 [00:04<00:00, 12.68it/s, train_acc=0.995, train_loss=0.0166, val_acc=0.992, val_loss=0.0177] \n",
      "73/100 epochs: 100%|██████████| 59/59 [00:05<00:00, 11.79it/s, train_acc=0.995, train_loss=0.0159, val_acc=0.994, val_loss=0.0178]\n",
      "74/100 epochs: 100%|██████████| 59/59 [00:04<00:00, 12.50it/s, train_acc=0.995, train_loss=0.016, val_acc=0.992, val_loss=0.0217]\n",
      "75/100 epochs: 100%|██████████| 59/59 [00:04<00:00, 12.51it/s, train_acc=0.995, train_loss=0.0158, val_acc=0.994, val_loss=0.0102]\n",
      "76/100 epochs: 100%|██████████| 59/59 [00:04<00:00, 12.78it/s, train_acc=0.995, train_loss=0.0149, val_acc=0.994, val_loss=0.0181] \n",
      "77/100 epochs: 100%|██████████| 59/59 [00:04<00:00, 11.91it/s, train_acc=0.995, train_loss=0.0153, val_acc=0.996, val_loss=0.0126] \n",
      "78/100 epochs: 100%|██████████| 59/59 [00:04<00:00, 12.77it/s, train_acc=0.995, train_loss=0.0141, val_acc=0.992, val_loss=0.0123] \n",
      "79/100 epochs: 100%|██████████| 59/59 [00:04<00:00, 12.74it/s, train_acc=0.995, train_loss=0.0142, val_acc=0.996, val_loss=0.00852]\n",
      "80/100 epochs: 100%|██████████| 59/59 [00:04<00:00, 12.74it/s, train_acc=0.995, train_loss=0.0144, val_acc=0.992, val_loss=0.0102] \n",
      "81/100 epochs: 100%|██████████| 59/59 [00:04<00:00, 12.43it/s, train_acc=0.995, train_loss=0.0139, val_acc=0.994, val_loss=0.0115] \n",
      "82/100 epochs: 100%|██████████| 59/59 [00:04<00:00, 12.60it/s, train_acc=0.995, train_loss=0.0132, val_acc=0.994, val_loss=0.0175]\n",
      "83/100 epochs: 100%|██████████| 59/59 [00:04<00:00, 12.85it/s, train_acc=0.995, train_loss=0.0136, val_acc=0.994, val_loss=0.00916]\n",
      "84/100 epochs: 100%|██████████| 59/59 [00:04<00:00, 11.91it/s, train_acc=0.995, train_loss=0.0146, val_acc=0.996, val_loss=0.00632]\n",
      "85/100 epochs: 100%|██████████| 59/59 [00:04<00:00, 12.85it/s, train_acc=0.995, train_loss=0.0141, val_acc=0.994, val_loss=0.00992]\n",
      "86/100 epochs: 100%|██████████| 59/59 [00:04<00:00, 12.74it/s, train_acc=0.995, train_loss=0.0151, val_acc=0.994, val_loss=0.0105]\n",
      "87/100 epochs: 100%|██████████| 59/59 [00:04<00:00, 12.58it/s, train_acc=0.995, train_loss=0.014, val_acc=0.996, val_loss=0.00854]\n",
      "88/100 epochs: 100%|██████████| 59/59 [00:04<00:00, 12.83it/s, train_acc=0.995, train_loss=0.0145, val_acc=0.996, val_loss=0.00774]\n",
      "89/100 epochs: 100%|██████████| 59/59 [00:04<00:00, 12.77it/s, train_acc=0.996, train_loss=0.0118, val_acc=0.99, val_loss=0.0149]  \n",
      "90/100 epochs: 100%|██████████| 59/59 [00:04<00:00, 12.41it/s, train_acc=0.995, train_loss=0.0152, val_acc=0.994, val_loss=0.00899]\n",
      "91/100 epochs: 100%|██████████| 59/59 [00:04<00:00, 12.61it/s, train_acc=0.995, train_loss=0.0136, val_acc=0.992, val_loss=0.0165]\n",
      "92/100 epochs: 100%|██████████| 59/59 [00:04<00:00, 12.67it/s, train_acc=0.995, train_loss=0.0136, val_acc=0.996, val_loss=0.00945]\n",
      "93/100 epochs: 100%|██████████| 59/59 [00:04<00:00, 12.77it/s, train_acc=0.996, train_loss=0.0134, val_acc=0.988, val_loss=0.0188] \n",
      "94/100 epochs: 100%|██████████| 59/59 [00:04<00:00, 12.78it/s, train_acc=0.995, train_loss=0.0138, val_acc=0.992, val_loss=0.0163] \n",
      "95/100 epochs: 100%|██████████| 59/59 [00:04<00:00, 12.60it/s, train_acc=0.996, train_loss=0.0125, val_acc=0.994, val_loss=0.0124]\n",
      "96/100 epochs: 100%|██████████| 59/59 [00:04<00:00, 12.76it/s, train_acc=0.995, train_loss=0.015, val_acc=0.996, val_loss=0.0063]\n",
      "97/100 epochs: 100%|██████████| 59/59 [00:04<00:00, 12.50it/s, train_acc=0.996, train_loss=0.0138, val_acc=0.996, val_loss=0.00878]\n",
      "98/100 epochs: 100%|██████████| 59/59 [00:04<00:00, 12.72it/s, train_acc=0.996, train_loss=0.012, val_acc=0.994, val_loss=0.00914]\n",
      "99/100 epochs: 100%|██████████| 59/59 [00:04<00:00, 12.74it/s, train_acc=0.996, train_loss=0.0115, val_acc=0.994, val_loss=0.00795]\n",
      "100/100 epochs: 100%|██████████| 59/59 [00:04<00:00, 12.64it/s, train_acc=0.996, train_loss=0.0127, val_acc=1, val_loss=0.00474] \n"
     ]
    }
   ],
   "source": [
    "from models.cnn import CNN\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.optim import Adam, lr_scheduler\n",
    "from torchvision import datasets,transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "\n",
    "device = torch.device(\"cuda\")\n",
    "root = \"./datasets\"\n",
    "download = os.path.exists(\"./datasets/MNIST\")\n",
    "\n",
    "model = CNN()\n",
    "model.to(device)\n",
    "\n",
    "trainset = datasets.MNIST(root=\"./datasets\", download=download, train=True, transform=transforms.ToTensor())\n",
    "testset = datasets.MNIST(root=\"./datasets\", download=download, train=False, transform=transforms.ToTensor())\n",
    "trainloader = DataLoader(trainset, shuffle=True, batch_size=1024)\n",
    "testloader = DataLoader(testset, shuffle=False, batch_size=128)\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = Adam(model.parameters(),lr=1e-3)\n",
    "\n",
    "epochs = 100\n",
    "best_val_acc = 0\n",
    "for e in range(epochs):\n",
    "    with tqdm(trainloader,desc=f\"{e+1}/{epochs} epochs\") as t:\n",
    "        running_correct = 0\n",
    "        running_loss = 0\n",
    "        running_total = 0\n",
    "        model.train()\n",
    "        for i, (x,y) in enumerate(t):\n",
    "            out = model(x.to(device))\n",
    "            loss = loss_fn(out,y.to(device))\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_correct += (out.max(dim=1)[1]==y.to(device)).sum().item()\n",
    "            running_loss += loss.item()*x.size(0)\n",
    "            running_total += x.size(0)\n",
    "            if i < len(trainloader)-1:\n",
    "                t.set_postfix({\n",
    "                    \"train_acc\": running_correct/running_total,\n",
    "                    \"train_loss\": running_loss/running_total\n",
    "                })\n",
    "            else:\n",
    "                model.eval()\n",
    "                val_correct = 0\n",
    "                val_loss = 0\n",
    "                val_total = 0\n",
    "                with torch.no_grad():\n",
    "                    for _, (x,y) in zip(range(4),testloader):\n",
    "                        out = model(x.to(device))\n",
    "                        loss = loss_fn(out,y.to(device))\n",
    "                        val_correct += (out.max(dim=1)[1]==y.to(device)).sum().item()\n",
    "                        val_loss += loss.item()*x.size(0)\n",
    "                        val_total += x.size(0)\n",
    "                        t.set_postfix({\n",
    "                            \"train_acc\": running_correct/running_total,\n",
    "                            \"train_loss\": running_loss/running_total,\n",
    "                            \"val_acc\": val_correct/val_total,\n",
    "                            \"val_loss\": val_loss/val_total\n",
    "                        })\n",
    "                    if val_correct/val_total >= best_val_acc:\n",
    "                        best_val_acc = val_correct/val_total\n",
    "                        torch.save(model.state_dict(), \"./model_weights/mnist_cnn_clean.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
