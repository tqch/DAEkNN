{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1/200 epochs: 100%|██████████| 391/391 [01:03<00:00,  6.20it/s, train_acc=0.22, train_loss=1.92, val_acc=0.291, val_loss=1.84]\n",
      "2/200 epochs: 100%|██████████| 391/391 [01:12<00:00,  5.39it/s, train_acc=0.342, train_loss=1.67, val_acc=0.39, val_loss=1.68] \n",
      "3/200 epochs: 100%|██████████| 391/391 [01:06<00:00,  5.91it/s, train_acc=0.453, train_loss=1.4, val_acc=0.456, val_loss=1.51]\n",
      "4/200 epochs: 100%|██████████| 391/391 [01:19<00:00,  4.93it/s, train_acc=0.58, train_loss=1.15, val_acc=0.508, val_loss=1.62]\n",
      "5/200 epochs: 100%|██████████| 391/391 [01:02<00:00,  6.23it/s, train_acc=0.676, train_loss=0.959, val_acc=0.551, val_loss=1.52]\n",
      "6/200 epochs: 100%|██████████| 391/391 [01:12<00:00,  5.37it/s, train_acc=0.722, train_loss=0.852, val_acc=0.619, val_loss=1.32]\n",
      "7/200 epochs: 100%|██████████| 391/391 [00:54<00:00,  7.13it/s, train_acc=0.75, train_loss=0.775, val_acc=0.717, val_loss=0.872]\n",
      "8/200 epochs: 100%|██████████| 391/391 [01:05<00:00,  5.93it/s, train_acc=0.769, train_loss=0.725, val_acc=0.664, val_loss=1.15]\n",
      "9/200 epochs: 100%|██████████| 391/391 [01:14<00:00,  5.22it/s, train_acc=0.78, train_loss=0.69, val_acc=0.705, val_loss=0.919]\n",
      "10/200 epochs: 100%|██████████| 391/391 [01:05<00:00,  5.94it/s, train_acc=0.79, train_loss=0.662, val_acc=0.718, val_loss=0.949]\n",
      "11/200 epochs: 100%|██████████| 391/391 [01:04<00:00,  6.08it/s, train_acc=0.799, train_loss=0.636, val_acc=0.69, val_loss=1.09] \n",
      "12/200 epochs: 100%|██████████| 391/391 [01:18<00:00,  5.01it/s, train_acc=0.801, train_loss=0.632, val_acc=0.689, val_loss=1.07] \n",
      "13/200 epochs: 100%|██████████| 391/391 [01:05<00:00,  6.00it/s, train_acc=0.81, train_loss=0.607, val_acc=0.762, val_loss=0.724]\n",
      "14/200 epochs: 100%|██████████| 391/391 [01:16<00:00,  5.13it/s, train_acc=0.814, train_loss=0.598, val_acc=0.724, val_loss=0.874]\n",
      "15/200 epochs: 100%|██████████| 391/391 [01:10<00:00,  5.51it/s, train_acc=0.814, train_loss=0.596, val_acc=0.754, val_loss=0.81] \n",
      "16/200 epochs: 100%|██████████| 391/391 [01:16<00:00,  5.12it/s, train_acc=0.822, train_loss=0.578, val_acc=0.744, val_loss=0.873]\n",
      "17/200 epochs: 100%|██████████| 391/391 [01:27<00:00,  4.46it/s, train_acc=0.824, train_loss=0.568, val_acc=0.618, val_loss=1.28]\n",
      "18/200 epochs: 100%|██████████| 391/391 [01:09<00:00,  5.66it/s, train_acc=0.825, train_loss=0.562, val_acc=0.749, val_loss=0.815]\n",
      "19/200 epochs: 100%|██████████| 391/391 [01:20<00:00,  4.86it/s, train_acc=0.827, train_loss=0.557, val_acc=0.772, val_loss=0.721]\n",
      "20/200 epochs: 100%|██████████| 391/391 [01:21<00:00,  4.80it/s, train_acc=0.83, train_loss=0.552, val_acc=0.704, val_loss=1.01]\n",
      "21/200 epochs: 100%|██████████| 391/391 [01:06<00:00,  5.91it/s, train_acc=0.833, train_loss=0.544, val_acc=0.787, val_loss=0.655]\n",
      "22/200 epochs: 100%|██████████| 391/391 [01:14<00:00,  5.22it/s, train_acc=0.834, train_loss=0.531, val_acc=0.764, val_loss=0.785]\n",
      "23/200 epochs: 100%|██████████| 391/391 [01:00<00:00,  6.51it/s, train_acc=0.833, train_loss=0.542, val_acc=0.772, val_loss=0.725]\n",
      "24/200 epochs: 100%|██████████| 391/391 [00:44<00:00,  8.73it/s, train_acc=0.837, train_loss=0.521, val_acc=0.769, val_loss=0.714]\n",
      "25/200 epochs: 100%|██████████| 391/391 [01:05<00:00,  6.01it/s, train_acc=0.838, train_loss=0.521, val_acc=0.78, val_loss=0.689] \n",
      "26/200 epochs: 100%|██████████| 391/391 [01:08<00:00,  5.68it/s, train_acc=0.842, train_loss=0.512, val_acc=0.74, val_loss=0.838] \n",
      "27/200 epochs: 100%|██████████| 391/391 [00:48<00:00,  8.01it/s, train_acc=0.84, train_loss=0.514, val_acc=0.754, val_loss=0.803]\n",
      "28/200 epochs: 100%|██████████| 391/391 [00:52<00:00,  7.51it/s, train_acc=0.842, train_loss=0.508, val_acc=0.811, val_loss=0.576]\n",
      "29/200 epochs: 100%|██████████| 391/391 [00:43<00:00,  8.97it/s, train_acc=0.844, train_loss=0.505, val_acc=0.663, val_loss=1.26]\n",
      "30/200 epochs: 100%|██████████| 391/391 [00:52<00:00,  7.52it/s, train_acc=0.846, train_loss=0.497, val_acc=0.815, val_loss=0.563]\n",
      "31/200 epochs: 100%|██████████| 391/391 [00:51<00:00,  7.56it/s, train_acc=0.847, train_loss=0.498, val_acc=0.814, val_loss=0.635]\n",
      "32/200 epochs: 100%|██████████| 391/391 [01:06<00:00,  5.91it/s, train_acc=0.844, train_loss=0.501, val_acc=0.771, val_loss=0.768]\n",
      "33/200 epochs: 100%|██████████| 391/391 [01:29<00:00,  4.36it/s, train_acc=0.843, train_loss=0.5, val_acc=0.745, val_loss=0.756]\n",
      "34/200 epochs: 100%|██████████| 391/391 [01:13<00:00,  5.32it/s, train_acc=0.845, train_loss=0.495, val_acc=0.801, val_loss=0.589]\n",
      "35/200 epochs: 100%|██████████| 391/391 [01:26<00:00,  4.50it/s, train_acc=0.85, train_loss=0.492, val_acc=0.734, val_loss=0.821]\n",
      "36/200 epochs: 100%|██████████| 391/391 [01:18<00:00,  5.01it/s, train_acc=0.851, train_loss=0.481, val_acc=0.842, val_loss=0.55] \n",
      "37/200 epochs: 100%|██████████| 391/391 [01:03<00:00,  6.19it/s, train_acc=0.849, train_loss=0.488, val_acc=0.742, val_loss=0.897]\n",
      "38/200 epochs: 100%|██████████| 391/391 [01:03<00:00,  6.18it/s, train_acc=0.851, train_loss=0.485, val_acc=0.736, val_loss=0.854]\n",
      "39/200 epochs: 100%|██████████| 391/391 [00:58<00:00,  6.67it/s, train_acc=0.85, train_loss=0.484, val_acc=0.757, val_loss=0.748]\n",
      "40/200 epochs: 100%|██████████| 391/391 [01:04<00:00,  6.04it/s, train_acc=0.853, train_loss=0.476, val_acc=0.809, val_loss=0.626]\n",
      "41/200 epochs: 100%|██████████| 391/391 [00:59<00:00,  6.61it/s, train_acc=0.852, train_loss=0.479, val_acc=0.765, val_loss=0.751]\n",
      "42/200 epochs: 100%|██████████| 391/391 [00:55<00:00,  7.07it/s, train_acc=0.853, train_loss=0.473, val_acc=0.754, val_loss=0.769]\n",
      "43/200 epochs: 100%|██████████| 391/391 [01:18<00:00,  5.01it/s, train_acc=0.854, train_loss=0.469, val_acc=0.813, val_loss=0.567]\n",
      "44/200 epochs: 100%|██████████| 391/391 [01:03<00:00,  6.12it/s, train_acc=0.852, train_loss=0.478, val_acc=0.768, val_loss=0.696]\n",
      "45/200 epochs: 100%|██████████| 391/391 [01:01<00:00,  6.39it/s, train_acc=0.853, train_loss=0.474, val_acc=0.741, val_loss=0.797]\n",
      "46/200 epochs: 100%|██████████| 391/391 [01:10<00:00,  5.52it/s, train_acc=0.854, train_loss=0.472, val_acc=0.779, val_loss=0.687]\n",
      "47/200 epochs: 100%|██████████| 391/391 [01:00<00:00,  6.49it/s, train_acc=0.853, train_loss=0.472, val_acc=0.81, val_loss=0.556] \n",
      "48/200 epochs: 100%|██████████| 391/391 [00:59<00:00,  6.53it/s, train_acc=0.856, train_loss=0.463, val_acc=0.806, val_loss=0.65] \n",
      "49/200 epochs: 100%|██████████| 391/391 [01:01<00:00,  6.31it/s, train_acc=0.855, train_loss=0.475, val_acc=0.752, val_loss=0.752]\n",
      "50/200 epochs: 100%|██████████| 391/391 [01:00<00:00,  6.49it/s, train_acc=0.854, train_loss=0.475, val_acc=0.687, val_loss=0.977]\n",
      "51/200 epochs: 100%|██████████| 391/391 [01:13<00:00,  5.34it/s, train_acc=0.854, train_loss=0.468, val_acc=0.778, val_loss=0.728]\n",
      "52/200 epochs: 100%|██████████| 391/391 [01:08<00:00,  5.75it/s, train_acc=0.857, train_loss=0.465, val_acc=0.776, val_loss=0.839]\n",
      "53/200 epochs: 100%|██████████| 391/391 [01:26<00:00,  4.54it/s, train_acc=0.857, train_loss=0.46, val_acc=0.783, val_loss=0.671]\n",
      "54/200 epochs: 100%|██████████| 391/391 [01:32<00:00,  4.23it/s, train_acc=0.858, train_loss=0.462, val_acc=0.688, val_loss=1.12]\n",
      "55/200 epochs: 100%|██████████| 391/391 [01:11<00:00,  5.48it/s, train_acc=0.856, train_loss=0.462, val_acc=0.766, val_loss=0.836]\n",
      "56/200 epochs: 100%|██████████| 391/391 [01:09<00:00,  5.59it/s, train_acc=0.857, train_loss=0.459, val_acc=0.8, val_loss=0.636]  \n",
      "57/200 epochs: 100%|██████████| 391/391 [01:20<00:00,  4.86it/s, train_acc=0.855, train_loss=0.464, val_acc=0.714, val_loss=0.97] \n",
      "58/200 epochs: 100%|██████████| 391/391 [01:00<00:00,  6.47it/s, train_acc=0.858, train_loss=0.456, val_acc=0.823, val_loss=0.548]\n",
      "59/200 epochs: 100%|██████████| 391/391 [01:23<00:00,  4.71it/s, train_acc=0.859, train_loss=0.454, val_acc=0.808, val_loss=0.635]\n",
      "60/200 epochs: 100%|██████████| 391/391 [01:21<00:00,  4.77it/s, train_acc=0.857, train_loss=0.456, val_acc=0.681, val_loss=1.11]\n",
      "61/200 epochs: 100%|██████████| 391/391 [01:18<00:00,  4.99it/s, train_acc=0.859, train_loss=0.458, val_acc=0.747, val_loss=0.8]  \n",
      "62/200 epochs: 100%|██████████| 391/391 [00:55<00:00,  6.99it/s, train_acc=0.86, train_loss=0.452, val_acc=0.833, val_loss=0.576]\n",
      "63/200 epochs: 100%|██████████| 391/391 [01:04<00:00,  6.05it/s, train_acc=0.862, train_loss=0.452, val_acc=0.808, val_loss=0.615]\n",
      "64/200 epochs: 100%|██████████| 391/391 [01:06<00:00,  5.88it/s, train_acc=0.861, train_loss=0.45, val_acc=0.809, val_loss=0.602]\n",
      "65/200 epochs: 100%|██████████| 391/391 [01:10<00:00,  5.53it/s, train_acc=0.857, train_loss=0.46, val_acc=0.717, val_loss=0.909]\n",
      "66/200 epochs: 100%|██████████| 391/391 [00:58<00:00,  6.63it/s, train_acc=0.859, train_loss=0.454, val_acc=0.782, val_loss=0.736]\n",
      "67/200 epochs: 100%|██████████| 391/391 [00:57<00:00,  6.75it/s, train_acc=0.86, train_loss=0.455, val_acc=0.808, val_loss=0.574]\n",
      "68/200 epochs: 100%|██████████| 391/391 [01:20<00:00,  4.85it/s, train_acc=0.86, train_loss=0.453, val_acc=0.817, val_loss=0.607]\n",
      "69/200 epochs: 100%|██████████| 391/391 [01:04<00:00,  6.09it/s, train_acc=0.861, train_loss=0.451, val_acc=0.747, val_loss=0.779]\n",
      "70/200 epochs: 100%|██████████| 391/391 [01:12<00:00,  5.36it/s, train_acc=0.86, train_loss=0.453, val_acc=0.811, val_loss=0.642]\n",
      "71/200 epochs: 100%|██████████| 391/391 [01:06<00:00,  5.91it/s, train_acc=0.861, train_loss=0.448, val_acc=0.807, val_loss=0.606]\n",
      "72/200 epochs: 100%|██████████| 391/391 [01:11<00:00,  5.46it/s, train_acc=0.859, train_loss=0.454, val_acc=0.841, val_loss=0.512]\n",
      "73/200 epochs: 100%|██████████| 391/391 [01:13<00:00,  5.34it/s, train_acc=0.863, train_loss=0.444, val_acc=0.785, val_loss=0.68] \n",
      "74/200 epochs: 100%|██████████| 391/391 [00:59<00:00,  6.62it/s, train_acc=0.86, train_loss=0.453, val_acc=0.734, val_loss=0.951]\n",
      "75/200 epochs: 100%|██████████| 391/391 [01:09<00:00,  5.64it/s, train_acc=0.862, train_loss=0.445, val_acc=0.77, val_loss=0.757] \n",
      "76/200 epochs: 100%|██████████| 391/391 [01:20<00:00,  4.83it/s, train_acc=0.862, train_loss=0.447, val_acc=0.762, val_loss=0.771]\n",
      "77/200 epochs: 100%|██████████| 391/391 [00:58<00:00,  6.74it/s, train_acc=0.861, train_loss=0.448, val_acc=0.826, val_loss=0.524]\n",
      "78/200 epochs: 100%|██████████| 391/391 [01:04<00:00,  6.09it/s, train_acc=0.857, train_loss=0.457, val_acc=0.633, val_loss=1.3] \n",
      "79/200 epochs: 100%|██████████| 391/391 [01:00<00:00,  6.44it/s, train_acc=0.861, train_loss=0.451, val_acc=0.759, val_loss=0.777]\n",
      "80/200 epochs: 100%|██████████| 391/391 [00:55<00:00,  7.00it/s, train_acc=0.863, train_loss=0.441, val_acc=0.832, val_loss=0.522]\n",
      "81/200 epochs: 100%|██████████| 391/391 [01:15<00:00,  5.19it/s, train_acc=0.86, train_loss=0.448, val_acc=0.758, val_loss=0.772]\n",
      "82/200 epochs: 100%|██████████| 391/391 [01:22<00:00,  4.75it/s, train_acc=0.86, train_loss=0.451, val_acc=0.784, val_loss=0.7]  \n",
      "83/200 epochs: 100%|██████████| 391/391 [00:54<00:00,  7.19it/s, train_acc=0.863, train_loss=0.447, val_acc=0.816, val_loss=0.551]\n",
      "84/200 epochs: 100%|██████████| 391/391 [01:03<00:00,  6.20it/s, train_acc=0.861, train_loss=0.443, val_acc=0.794, val_loss=0.711]\n",
      "85/200 epochs: 100%|██████████| 391/391 [01:10<00:00,  5.53it/s, train_acc=0.863, train_loss=0.444, val_acc=0.764, val_loss=0.736]\n",
      "86/200 epochs: 100%|██████████| 391/391 [01:03<00:00,  6.11it/s, train_acc=0.862, train_loss=0.448, val_acc=0.847, val_loss=0.506]\n",
      "87/200 epochs: 100%|██████████| 391/391 [01:03<00:00,  6.13it/s, train_acc=0.864, train_loss=0.441, val_acc=0.75, val_loss=0.801] \n",
      "88/200 epochs: 100%|██████████| 391/391 [01:26<00:00,  4.52it/s, train_acc=0.861, train_loss=0.45, val_acc=0.828, val_loss=0.584]\n",
      "89/200 epochs: 100%|██████████| 391/391 [00:59<00:00,  6.55it/s, train_acc=0.862, train_loss=0.446, val_acc=0.791, val_loss=0.647]\n",
      "90/200 epochs: 100%|██████████| 391/391 [00:52<00:00,  7.51it/s, train_acc=0.858, train_loss=0.456, val_acc=0.744, val_loss=0.774]\n",
      "91/200 epochs: 100%|██████████| 391/391 [01:05<00:00,  5.98it/s, train_acc=0.865, train_loss=0.433, val_acc=0.832, val_loss=0.545]\n",
      "92/200 epochs: 100%|██████████| 391/391 [01:12<00:00,  5.41it/s, train_acc=0.864, train_loss=0.439, val_acc=0.801, val_loss=0.629]\n",
      "93/200 epochs: 100%|██████████| 391/391 [01:18<00:00,  4.98it/s, train_acc=0.862, train_loss=0.444, val_acc=0.631, val_loss=1.26]\n",
      "94/200 epochs: 100%|██████████| 391/391 [01:00<00:00,  6.41it/s, train_acc=0.862, train_loss=0.444, val_acc=0.79, val_loss=0.725] \n",
      "95/200 epochs: 100%|██████████| 391/391 [00:56<00:00,  6.91it/s, train_acc=0.862, train_loss=0.442, val_acc=0.784, val_loss=0.691]\n",
      "96/200 epochs: 100%|██████████| 391/391 [01:16<00:00,  5.14it/s, train_acc=0.864, train_loss=0.436, val_acc=0.808, val_loss=0.684]\n",
      "97/200 epochs: 100%|██████████| 391/391 [01:29<00:00,  4.35it/s, train_acc=0.864, train_loss=0.438, val_acc=0.836, val_loss=0.494]\n",
      "98/200 epochs: 100%|██████████| 391/391 [00:57<00:00,  6.83it/s, train_acc=0.864, train_loss=0.439, val_acc=0.818, val_loss=0.593]\n",
      "99/200 epochs: 100%|██████████| 391/391 [01:01<00:00,  6.38it/s, train_acc=0.865, train_loss=0.438, val_acc=0.775, val_loss=0.681]\n",
      "100/200 epochs: 100%|██████████| 391/391 [01:06<00:00,  5.87it/s, train_acc=0.864, train_loss=0.445, val_acc=0.792, val_loss=0.669]\n",
      "101/200 epochs: 100%|██████████| 391/391 [01:15<00:00,  5.19it/s, train_acc=0.923, train_loss=0.248, val_acc=0.914, val_loss=0.248]\n",
      "102/200 epochs: 100%|██████████| 391/391 [01:16<00:00,  5.10it/s, train_acc=0.938, train_loss=0.194, val_acc=0.921, val_loss=0.234]\n",
      "103/200 epochs: 100%|██████████| 391/391 [00:59<00:00,  6.62it/s, train_acc=0.946, train_loss=0.17, val_acc=0.921, val_loss=0.224]\n",
      "104/200 epochs: 100%|██████████| 391/391 [01:05<00:00,  5.97it/s, train_acc=0.952, train_loss=0.15, val_acc=0.923, val_loss=0.227]\n",
      "105/200 epochs: 100%|██████████| 391/391 [01:13<00:00,  5.29it/s, train_acc=0.954, train_loss=0.141, val_acc=0.928, val_loss=0.215]\n",
      "106/200 epochs: 100%|██████████| 391/391 [01:10<00:00,  5.52it/s, train_acc=0.959, train_loss=0.129, val_acc=0.92, val_loss=0.242] \n",
      "107/200 epochs: 100%|██████████| 391/391 [01:18<00:00,  4.97it/s, train_acc=0.961, train_loss=0.121, val_acc=0.928, val_loss=0.227]\n",
      "108/200 epochs: 100%|██████████| 391/391 [00:56<00:00,  6.93it/s, train_acc=0.963, train_loss=0.115, val_acc=0.926, val_loss=0.233]\n",
      "109/200 epochs: 100%|██████████| 391/391 [01:07<00:00,  5.78it/s, train_acc=0.966, train_loss=0.108, val_acc=0.924, val_loss=0.24] \n",
      "110/200 epochs: 100%|██████████| 391/391 [01:30<00:00,  4.34it/s, train_acc=0.968, train_loss=0.102, val_acc=0.924, val_loss=0.234]\n",
      "111/200 epochs: 100%|██████████| 391/391 [01:05<00:00,  5.99it/s, train_acc=0.97, train_loss=0.0958, val_acc=0.92, val_loss=0.237] \n",
      "112/200 epochs: 100%|██████████| 391/391 [01:01<00:00,  6.37it/s, train_acc=0.97, train_loss=0.0906, val_acc=0.921, val_loss=0.262]\n",
      "113/200 epochs: 100%|██████████| 391/391 [00:58<00:00,  6.69it/s, train_acc=0.972, train_loss=0.0889, val_acc=0.924, val_loss=0.245]\n",
      "114/200 epochs: 100%|██████████| 391/391 [00:50<00:00,  7.69it/s, train_acc=0.972, train_loss=0.0863, val_acc=0.925, val_loss=0.258]\n",
      "115/200 epochs: 100%|██████████| 391/391 [00:55<00:00,  6.99it/s, train_acc=0.973, train_loss=0.0831, val_acc=0.924, val_loss=0.263]\n",
      "116/200 epochs: 100%|██████████| 391/391 [00:51<00:00,  7.59it/s, train_acc=0.974, train_loss=0.081, val_acc=0.924, val_loss=0.285]\n",
      "117/200 epochs: 100%|██████████| 391/391 [00:48<00:00,  8.04it/s, train_acc=0.975, train_loss=0.0771, val_acc=0.934, val_loss=0.243]\n",
      "118/200 epochs: 100%|██████████| 391/391 [01:10<00:00,  5.52it/s, train_acc=0.976, train_loss=0.0767, val_acc=0.922, val_loss=0.296]\n",
      "119/200 epochs: 100%|██████████| 391/391 [00:51<00:00,  7.64it/s, train_acc=0.975, train_loss=0.0808, val_acc=0.917, val_loss=0.287]\n",
      "120/200 epochs: 100%|██████████| 391/391 [01:11<00:00,  5.48it/s, train_acc=0.976, train_loss=0.0752, val_acc=0.906, val_loss=0.306]\n",
      "121/200 epochs: 100%|██████████| 391/391 [00:53<00:00,  7.36it/s, train_acc=0.975, train_loss=0.0775, val_acc=0.918, val_loss=0.281]\n",
      "122/200 epochs: 100%|██████████| 391/391 [00:59<00:00,  6.52it/s, train_acc=0.975, train_loss=0.078, val_acc=0.922, val_loss=0.259]\n",
      "123/200 epochs: 100%|██████████| 391/391 [00:55<00:00,  7.01it/s, train_acc=0.976, train_loss=0.0778, val_acc=0.912, val_loss=0.31] \n",
      "124/200 epochs: 100%|██████████| 391/391 [00:56<00:00,  6.93it/s, train_acc=0.975, train_loss=0.0764, val_acc=0.915, val_loss=0.308]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "125/200 epochs: 100%|██████████| 391/391 [01:03<00:00,  6.13it/s, train_acc=0.975, train_loss=0.076, val_acc=0.912, val_loss=0.341]\n",
      "126/200 epochs: 100%|██████████| 391/391 [00:46<00:00,  8.45it/s, train_acc=0.975, train_loss=0.077, val_acc=0.918, val_loss=0.301]\n",
      "127/200 epochs: 100%|██████████| 391/391 [01:03<00:00,  6.16it/s, train_acc=0.976, train_loss=0.0763, val_acc=0.913, val_loss=0.327]\n",
      "128/200 epochs: 100%|██████████| 391/391 [00:47<00:00,  8.15it/s, train_acc=0.975, train_loss=0.0773, val_acc=0.913, val_loss=0.318]\n",
      "129/200 epochs: 100%|██████████| 391/391 [00:44<00:00,  8.73it/s, train_acc=0.976, train_loss=0.0735, val_acc=0.912, val_loss=0.299]\n",
      "130/200 epochs: 100%|██████████| 391/391 [00:54<00:00,  7.21it/s, train_acc=0.977, train_loss=0.0724, val_acc=0.922, val_loss=0.26] \n",
      "131/200 epochs: 100%|██████████| 391/391 [01:11<00:00,  5.49it/s, train_acc=0.975, train_loss=0.0784, val_acc=0.916, val_loss=0.296]\n",
      "132/200 epochs: 100%|██████████| 391/391 [01:24<00:00,  4.63it/s, train_acc=0.975, train_loss=0.0774, val_acc=0.906, val_loss=0.33] \n",
      "133/200 epochs: 100%|██████████| 391/391 [01:12<00:00,  5.36it/s, train_acc=0.976, train_loss=0.077, val_acc=0.918, val_loss=0.288]\n",
      "134/200 epochs: 100%|██████████| 391/391 [01:13<00:00,  5.34it/s, train_acc=0.976, train_loss=0.077, val_acc=0.911, val_loss=0.3]  \n",
      "135/200 epochs: 100%|██████████| 391/391 [01:12<00:00,  5.41it/s, train_acc=0.975, train_loss=0.0783, val_acc=0.906, val_loss=0.32] \n",
      "136/200 epochs: 100%|██████████| 391/391 [01:09<00:00,  5.63it/s, train_acc=0.976, train_loss=0.0753, val_acc=0.91, val_loss=0.32]  \n",
      "137/200 epochs: 100%|██████████| 391/391 [01:10<00:00,  5.57it/s, train_acc=0.976, train_loss=0.0759, val_acc=0.918, val_loss=0.29] \n",
      "138/200 epochs: 100%|██████████| 391/391 [01:13<00:00,  5.33it/s, train_acc=0.974, train_loss=0.0826, val_acc=0.904, val_loss=0.349]\n",
      "139/200 epochs: 100%|██████████| 391/391 [01:22<00:00,  4.75it/s, train_acc=0.976, train_loss=0.0761, val_acc=0.904, val_loss=0.361]\n",
      "140/200 epochs: 100%|██████████| 391/391 [00:54<00:00,  7.14it/s, train_acc=0.975, train_loss=0.0762, val_acc=0.918, val_loss=0.326]\n",
      "141/200 epochs: 100%|██████████| 391/391 [00:50<00:00,  7.80it/s, train_acc=0.973, train_loss=0.0848, val_acc=0.909, val_loss=0.299]\n",
      "142/200 epochs: 100%|██████████| 391/391 [00:51<00:00,  7.57it/s, train_acc=0.975, train_loss=0.0791, val_acc=0.903, val_loss=0.34] \n",
      "143/200 epochs: 100%|██████████| 391/391 [00:47<00:00,  8.28it/s, train_acc=0.975, train_loss=0.0793, val_acc=0.919, val_loss=0.309]\n",
      "144/200 epochs: 100%|██████████| 391/391 [00:55<00:00,  7.10it/s, train_acc=0.976, train_loss=0.0781, val_acc=0.907, val_loss=0.348]\n",
      "145/200 epochs: 100%|██████████| 391/391 [00:43<00:00,  9.02it/s, train_acc=0.975, train_loss=0.0791, val_acc=0.902, val_loss=0.369]\n",
      "146/200 epochs: 100%|██████████| 391/391 [00:55<00:00,  7.04it/s, train_acc=0.976, train_loss=0.0786, val_acc=0.898, val_loss=0.383]\n",
      "147/200 epochs: 100%|██████████| 391/391 [00:54<00:00,  7.20it/s, train_acc=0.976, train_loss=0.0789, val_acc=0.905, val_loss=0.367]\n",
      "148/200 epochs: 100%|██████████| 391/391 [01:01<00:00,  6.38it/s, train_acc=0.973, train_loss=0.0831, val_acc=0.89, val_loss=0.421] \n",
      "149/200 epochs: 100%|██████████| 391/391 [01:05<00:00,  5.97it/s, train_acc=0.975, train_loss=0.0793, val_acc=0.916, val_loss=0.304]\n",
      "150/200 epochs: 100%|██████████| 391/391 [01:03<00:00,  6.19it/s, train_acc=0.975, train_loss=0.0788, val_acc=0.87, val_loss=0.5]   \n",
      "151/200 epochs: 100%|██████████| 391/391 [00:57<00:00,  6.79it/s, train_acc=0.973, train_loss=0.0835, val_acc=0.901, val_loss=0.391]\n",
      "152/200 epochs: 100%|██████████| 391/391 [01:04<00:00,  6.08it/s, train_acc=0.974, train_loss=0.0795, val_acc=0.931, val_loss=0.261]\n",
      "153/200 epochs: 100%|██████████| 391/391 [00:48<00:00,  8.09it/s, train_acc=0.975, train_loss=0.0802, val_acc=0.91, val_loss=0.335] \n",
      "154/200 epochs: 100%|██████████| 391/391 [00:51<00:00,  7.53it/s, train_acc=0.975, train_loss=0.0789, val_acc=0.902, val_loss=0.38] \n",
      "155/200 epochs: 100%|██████████| 391/391 [01:05<00:00,  6.01it/s, train_acc=0.974, train_loss=0.0831, val_acc=0.904, val_loss=0.336]\n",
      "156/200 epochs: 100%|██████████| 391/391 [01:01<00:00,  6.39it/s, train_acc=0.976, train_loss=0.0758, val_acc=0.916, val_loss=0.342]\n",
      "157/200 epochs: 100%|██████████| 391/391 [01:02<00:00,  6.22it/s, train_acc=0.976, train_loss=0.074, val_acc=0.878, val_loss=0.467]\n",
      "158/200 epochs: 100%|██████████| 391/391 [00:59<00:00,  6.59it/s, train_acc=0.974, train_loss=0.0837, val_acc=0.907, val_loss=0.354]\n",
      "159/200 epochs: 100%|██████████| 391/391 [01:07<00:00,  5.79it/s, train_acc=0.976, train_loss=0.0783, val_acc=0.913, val_loss=0.329]\n",
      "160/200 epochs: 100%|██████████| 391/391 [00:54<00:00,  7.20it/s, train_acc=0.975, train_loss=0.0772, val_acc=0.899, val_loss=0.383]\n",
      "161/200 epochs: 100%|██████████| 391/391 [01:01<00:00,  6.35it/s, train_acc=0.975, train_loss=0.0788, val_acc=0.922, val_loss=0.291]\n",
      "162/200 epochs: 100%|██████████| 391/391 [01:08<00:00,  5.70it/s, train_acc=0.977, train_loss=0.0753, val_acc=0.918, val_loss=0.328]\n",
      "163/200 epochs: 100%|██████████| 391/391 [01:09<00:00,  5.59it/s, train_acc=0.976, train_loss=0.0744, val_acc=0.896, val_loss=0.367]\n",
      "164/200 epochs: 100%|██████████| 391/391 [01:01<00:00,  6.31it/s, train_acc=0.975, train_loss=0.0791, val_acc=0.911, val_loss=0.321]\n",
      "165/200 epochs: 100%|██████████| 391/391 [00:57<00:00,  6.82it/s, train_acc=0.975, train_loss=0.0781, val_acc=0.906, val_loss=0.36] \n",
      "166/200 epochs: 100%|██████████| 391/391 [01:08<00:00,  5.67it/s, train_acc=0.974, train_loss=0.0799, val_acc=0.914, val_loss=0.312]\n",
      "167/200 epochs: 100%|██████████| 391/391 [01:08<00:00,  5.69it/s, train_acc=0.975, train_loss=0.0767, val_acc=0.905, val_loss=0.356]\n",
      "168/200 epochs: 100%|██████████| 391/391 [01:00<00:00,  6.51it/s, train_acc=0.975, train_loss=0.0791, val_acc=0.911, val_loss=0.331]\n",
      "169/200 epochs: 100%|██████████| 391/391 [01:07<00:00,  5.80it/s, train_acc=0.975, train_loss=0.0814, val_acc=0.894, val_loss=0.341]\n",
      "170/200 epochs: 100%|██████████| 391/391 [00:59<00:00,  6.57it/s, train_acc=0.976, train_loss=0.0755, val_acc=0.905, val_loss=0.33] \n",
      "171/200 epochs: 100%|██████████| 391/391 [01:05<00:00,  6.00it/s, train_acc=0.976, train_loss=0.075, val_acc=0.922, val_loss=0.293]\n",
      "172/200 epochs: 100%|██████████| 391/391 [00:58<00:00,  6.70it/s, train_acc=0.974, train_loss=0.0795, val_acc=0.899, val_loss=0.371]\n",
      "173/200 epochs: 100%|██████████| 391/391 [01:07<00:00,  5.77it/s, train_acc=0.977, train_loss=0.0713, val_acc=0.905, val_loss=0.345]\n",
      "174/200 epochs: 100%|██████████| 391/391 [00:57<00:00,  6.75it/s, train_acc=0.976, train_loss=0.0772, val_acc=0.907, val_loss=0.325]\n",
      "175/200 epochs: 100%|██████████| 391/391 [01:05<00:00,  5.98it/s, train_acc=0.975, train_loss=0.0776, val_acc=0.927, val_loss=0.27] \n",
      "176/200 epochs: 100%|██████████| 391/391 [00:54<00:00,  7.17it/s, train_acc=0.977, train_loss=0.0725, val_acc=0.917, val_loss=0.327]\n",
      "177/200 epochs: 100%|██████████| 391/391 [01:07<00:00,  5.78it/s, train_acc=0.974, train_loss=0.0813, val_acc=0.907, val_loss=0.316]\n",
      "178/200 epochs: 100%|██████████| 391/391 [00:57<00:00,  6.77it/s, train_acc=0.976, train_loss=0.0753, val_acc=0.912, val_loss=0.344]\n",
      "179/200 epochs: 100%|██████████| 391/391 [00:46<00:00,  8.46it/s, train_acc=0.976, train_loss=0.0773, val_acc=0.896, val_loss=0.387]\n",
      "180/200 epochs: 100%|██████████| 391/391 [00:51<00:00,  7.55it/s, train_acc=0.976, train_loss=0.0756, val_acc=0.91, val_loss=0.317] \n",
      "181/200 epochs: 100%|██████████| 391/391 [01:00<00:00,  6.48it/s, train_acc=0.976, train_loss=0.0763, val_acc=0.913, val_loss=0.298]\n",
      "182/200 epochs: 100%|██████████| 391/391 [00:58<00:00,  6.67it/s, train_acc=0.977, train_loss=0.073, val_acc=0.91, val_loss=0.345] \n",
      "183/200 epochs: 100%|██████████| 391/391 [00:46<00:00,  8.39it/s, train_acc=0.977, train_loss=0.0742, val_acc=0.916, val_loss=0.294]\n",
      "184/200 epochs: 100%|██████████| 391/391 [00:55<00:00,  7.09it/s, train_acc=0.977, train_loss=0.0717, val_acc=0.904, val_loss=0.36] \n",
      "185/200 epochs: 100%|██████████| 391/391 [00:59<00:00,  6.56it/s, train_acc=0.977, train_loss=0.0737, val_acc=0.915, val_loss=0.311]\n",
      "186/200 epochs: 100%|██████████| 391/391 [00:53<00:00,  7.31it/s, train_acc=0.977, train_loss=0.0738, val_acc=0.902, val_loss=0.342]\n",
      "187/200 epochs: 100%|██████████| 391/391 [00:36<00:00, 10.63it/s, train_acc=0.977, train_loss=0.0726, val_acc=0.91, val_loss=0.349] \n",
      "188/200 epochs: 100%|██████████| 391/391 [00:50<00:00,  7.69it/s, train_acc=0.977, train_loss=0.0722, val_acc=0.906, val_loss=0.338]\n",
      "189/200 epochs: 100%|██████████| 391/391 [00:50<00:00,  7.68it/s, train_acc=0.979, train_loss=0.0687, val_acc=0.9, val_loss=0.373]  \n",
      "190/200 epochs: 100%|██████████| 391/391 [01:07<00:00,  5.77it/s, train_acc=0.976, train_loss=0.0724, val_acc=0.907, val_loss=0.384]\n",
      "191/200 epochs: 100%|██████████| 391/391 [00:55<00:00,  7.03it/s, train_acc=0.976, train_loss=0.0729, val_acc=0.911, val_loss=0.325]\n",
      "192/200 epochs: 100%|██████████| 391/391 [01:03<00:00,  6.17it/s, train_acc=0.977, train_loss=0.0728, val_acc=0.914, val_loss=0.312]\n",
      "193/200 epochs: 100%|██████████| 391/391 [00:56<00:00,  6.90it/s, train_acc=0.977, train_loss=0.0701, val_acc=0.904, val_loss=0.359]\n",
      "194/200 epochs: 100%|██████████| 391/391 [00:58<00:00,  6.63it/s, train_acc=0.977, train_loss=0.0742, val_acc=0.907, val_loss=0.331]\n",
      "195/200 epochs: 100%|██████████| 391/391 [00:55<00:00,  7.05it/s, train_acc=0.978, train_loss=0.0708, val_acc=0.915, val_loss=0.333]\n",
      "196/200 epochs: 100%|██████████| 391/391 [00:52<00:00,  7.44it/s, train_acc=0.976, train_loss=0.0729, val_acc=0.914, val_loss=0.33] \n",
      "197/200 epochs:  65%|██████▌   | 256/391 [00:31<00:12, 11.04it/s, train_acc=0.978, train_loss=0.0719]"
     ]
    }
   ],
   "source": [
    "from models.vgg import VGG16\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.optim import SGD, lr_scheduler\n",
    "from torchvision import datasets,transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "\n",
    "device = torch.device(\"cuda\")\n",
    "root = \"./datasets\"\n",
    "download = os.path.exists(\"./datasets/cifar-10-batches-py\")\n",
    "\n",
    "model = VGG16()\n",
    "model.to(device)\n",
    "\n",
    "transform_train = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.RandomHorizontalFlip(p=0.5),\n",
    "    transforms.RandomCrop(size=32, padding=4)\n",
    "])\n",
    "\n",
    "transform_test = transforms.ToTensor()\n",
    "\n",
    "trainset = datasets.CIFAR10(root=\"./datasets\", download=False, train=True, transform=transform_train)\n",
    "testset = datasets.CIFAR10(root=\"./datasets\", download=False, train=False, transform=transform_test)\n",
    "trainloader = DataLoader(trainset, shuffle=True, batch_size=128)\n",
    "testloader = DataLoader(testset, shuffle=False, batch_size=256)\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = SGD(model.parameters(),lr=0.1,momentum=0.9,weight_decay=5e-4,nesterov=True)\n",
    "scheduler = lr_scheduler.StepLR(optimizer,step_size=100,gamma=0.1)\n",
    "\n",
    "epochs = 200\n",
    "best_val_acc = 0\n",
    "for e in range(epochs):\n",
    "    with tqdm(trainloader,desc=f\"{e+1}/{epochs} epochs\") as t:\n",
    "        running_correct = 0\n",
    "        running_loss = 0\n",
    "        running_total = 0\n",
    "        model.train()\n",
    "        for i, (x,y) in enumerate(t):\n",
    "            out = model(x.to(device))\n",
    "            loss = loss_fn(out,y.to(device))\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_correct += (out.max(dim=1)[1]==y.to(device)).sum().item()\n",
    "            running_loss += loss.item()*x.size(0)\n",
    "            running_total += x.size(0)\n",
    "            if i < len(trainloader)-1:\n",
    "                t.set_postfix({\n",
    "                    \"train_acc\": running_correct/running_total,\n",
    "                    \"train_loss\": running_loss/running_total\n",
    "                })\n",
    "            else:\n",
    "                scheduler.step()\n",
    "                model.eval()\n",
    "                val_correct = 0\n",
    "                val_loss = 0\n",
    "                val_total = 0\n",
    "                with torch.no_grad():\n",
    "                    for _, (x,y) in zip(range(4),testloader):\n",
    "                        out = model(x.to(device))\n",
    "                        loss = loss_fn(out,y.to(device))\n",
    "                        val_correct += (out.max(dim=1)[1]==y.to(device)).sum().item()\n",
    "                        val_loss += loss.item()*x.size(0)\n",
    "                        val_total += x.size(0)\n",
    "                        t.set_postfix({\n",
    "                            \"train_acc\": running_correct/running_total,\n",
    "                            \"train_loss\": running_loss/running_total,\n",
    "                            \"val_acc\": val_correct/val_total,\n",
    "                            \"val_loss\": val_loss/val_total\n",
    "                        })\n",
    "                    if val_correct/val_total > best_val_acc:\n",
    "                        best_val_acc = val_correct/val_total\n",
    "                        torch.save(model.state_dict(), \"./model_weights/cifar_vgg_clean.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
